{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9d54a3",
   "metadata": {},
   "source": [
    "# Arrays, cellular automata, and percolation \n",
    "## (Answers by David Miles Testa, dmt2943)\n",
    "\n",
    "Imports: Make sure these are installed in your conda env, and that the conda env is active in your notebook\n",
    "+ numpy\n",
    "+ matplotlib\n",
    "+ scipy\n",
    "+ jupyter\n",
    "\n",
    "For interactive plots:\n",
    "\n",
    "+ ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee03d2d-906b-4dee-aee1-b48f2a17a887",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a02d70",
   "metadata": {},
   "source": [
    "# The Abelian sandpile\n",
    "\n",
    "### Background\n",
    "\n",
    "We are going to implement the celebrated [Bak-Tang-Wiesenfeld model](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.59.381), also known as the \"Abelian sandpile.\" This cellular automaton describes a lattice in which sand grains are continuously dropped onto random locations at a fixed rate, resulting in the formation of random sandpiles. When the sandpiles grow too high, they topple, resulting in avalanches that distribute grains to all of their neighbors.\n",
    "\n",
    "If we denote the number of grains at a site $(x, y)$ as $z(x, y)$, a single \"topple\" event of the BTW model has the following update rule, which triggers only when $z \\geq 4$.\n",
    "\n",
    "$$\n",
    "z(x, y) \\rightarrow z(x, y) - 4\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{lr}\n",
    "    z(x + 1, y) \\leftarrow z(x + 1, y) + 1    \\\\\n",
    "    z(x - 1, y) \\leftarrow z(x - 1, y) + 1    \\\\\n",
    "    z(x, y + 1) \\leftarrow z(x, y + 1) + 1    \\\\\n",
    "    z(x, y - 1) \\leftarrow z(x, y - 1) + 1    \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "A topple event thus consists of a single site decreasing in height by four grains, and then distributing these grains to each of its north, south, east, and west neighbors---but not its diagonal neighbors.\n",
    "\n",
    "After a single topple event, the entire lattice is checked again to see if any other sites now have $z \\geq 4$, in which case those sites are toppled, too. If a site located at the boundary of the domain topples, then any grains that would go out of bounds are assumed to be permanently lost from the system. After all sites reach a state where $z \\leq 4$, the avalanche has concluded. We then add a sand grain to a random new site, and calculate any new resulting avalanches.\n",
    "\n",
    "This idealized system has several interesting properties: the continuous addition of grains represents a slow-timescale driving process, which effectively injects energy into the system. The avalances represent fast-timescale response dynamics, and the grains that fall off the edges represent dissipation---they prevent avalanches from continuing forever undriven. Despite its seeming simplicity, the BTK model represents perhaps the earliest widely-studied toy model of \"self-organized criticality,\" a well-known hypothesis in nonequilibrium statistical physics that driven, dissipative systems tend to tune themselves into maximally-critical states (there are always sandpiles on the verge of toppling). The sandpile has been used as a thought experiment describing an incredible array of diverse systems, including: starts and stops in dragging friction, [earthquakes](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/JB094iB11p15635), timings between geyser eruptions, [timings of pulsar glitches](https://arxiv.org/abs/1403.6528), [fluctuations in an ultracold atomic gas](https://www.nature.com/articles/s41586-019-1908-6), [neuronal activity patterns in the brain](https://www.frontiersin.org/articles/10.3389/fnsys.2014.00166/full), [flux pinning](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.67.919), and many other areas.\n",
    "\n",
    "A simple signature of self-organized-criticality observed in the sandpile model, which also represents an easy readout for experimental data, is the appearance of $1/f$ noise in the system's power spectrum, where $f$ denotes frequency. This distribution implies that avalanche durations have a skewed distribution, where larger events happen less frequently. For an experimental system, this results in \"crackling\" or brown noise in the detector. In the BTW model, the authors note that a $1/f$ distribution of rare events in the frequency corresponds to a $1/T$ distribution of waiting times between rare events. \n",
    "\n",
    "Here we will implement the BTW model, and then test for the appearance of $1/f$ noise.\n",
    "\n",
    "## To Do:\n",
    "\n",
    "1. Implement the Abelian Sandpile model and simulate its dynamics. I've included a template of the iterative solution below, although feel free to re-factor if you would prefer to implement the problem a different way. To my knowledge, there are three different ways to implement the Abelian sandpile:\n",
    "    + The iterative solution involves adding a grain and then repeatedly checking the lattice for piles to topple\n",
    "    + The recursive depth-first-search solution adds a grain and then traces the avalanche that results from each grain toppled by the initial addition.\n",
    "    + The breadth-first-search solution adds a grain and then simultaneously tracks the four potential avalanches that result from that single grain.\n",
    "2. Using the code included below, show that avalanche durations exhibit a $1/T^\\alpha$ distribution, where $\\alpha$ is some constant.\n",
    "3. If a single image of the sandpile has size $N$ (the total number of lattice sites), what do you expect to be the worst-case scaling of the runtime of your algorithm? What about the expected scaling of memory usage?\n",
    "4. You may have noticed that the waiting time and avalanche size distribution exhibit anomalous scaling in their tails, as visible as a small second peak near the extreme end of the distribution. What causes this effect?\n",
    "5. (Hard, optional) Try [vectorizing](https://realpython.com/numpy-array-programming/) your sandpile implementation, in order to reduce the number of \"for\" loops used in your implementation. How does vectorization affect the runtime?\n",
    "\n",
    "**If any experienced student wants to try to implement the Kramer & Marder paper discussed below instead of doing the BTK model, feel free to attempt it. I don't have a solution for it, but I would love to see one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3d42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5073e59a",
   "metadata": {},
   "source": [
    "## My Answers to the Sandpiles Questions:\n",
    "\n",
    "1. I implemented a method for the cascade/avalanche that (from your description above) seems to be a recursive depth-first method. It reproduces the same $\\frac{1}{T^{\\alpha}}$ distributions that Prof. Gilpin's code creates.\n",
    "\n",
    "2. I added some code below in the plotting block that fits a curve of the form $\\frac{B}{T^{\\alpha}}$ to the avalanche duration data, where B is a normalisation and $\\alpha$ is the scaling. The code calculates a fit of $\\alpha = 1.77536162$ with a corresponding covariance matric entry of $7.71699480\\times 10^{-3}$ which implies a good fit. We can therefore conclude that a $T^{-\\alpha}$ scaling is appropriate.\n",
    "\n",
    "3. Since the number of grid points scales like $N\\times N$, I would expect my algorithm to show a $N^2$ runtime scaling (as worst comes to worst we have to search the whole grid), but with a low coefficient out front due to it being a breadth first search through the grid. I added some code below to verify this experimentally, which it does. Since I store the whole grid, I would also expect my algorithm to have $N^2$ memory usage scaling. \n",
    "\n",
    "4. This is just a guess, but I assume it has something to do with the boundary conditions? The extra bump at the end of the waiting time distribution seems to me like the grid settles down after a while, with the sand being evenly distributed. It would then take longer for any single grain to start a cascade, at which point the whole grid would topple. I see this as there being a typical timescale where grid has smaller avalanches that spread the sand around evenly, and then a long timescale where the evenly spread sand reaches 4 grains almost everywhere, and then topples all at once. \n",
    "\n",
    "5. I tried vectorising (see the code below), and for the life of me I can't work out why it doesn't reproduce the same results as my recursive code. It almost exactly reproduces the $\\alpha$ coefficient, but not the exact same final state. My vectorisation basically adds zeros around the rim of the grid so that I can create a stencil to add grains to the gridpoints that need to topple (see the code for more detail). Vectorisation in this case would just reduce the coefficient out front of the $N^2$ runtime scaling. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba7c649-b71a-4741-b339-406690db8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbelianSandpile: \n",
    "    \"\"\"\n",
    "    An Abelian sandpile model simulation. The sandpile is initialized with a random\n",
    "    number of grains at each lattice site. Then, a single grain is dropped at a random\n",
    "    location. The sandpile is then allowed to evolve until it is stable. This process\n",
    "    is repeated n_step times.\n",
    "\n",
    "    A single step of the simulation consists of two stages: a random sand grain is \n",
    "    dropped onto the lattice at a random location. Then, a set of avalanches occurs\n",
    "    causing sandgrains to get redistributed to their neighboring locations.\n",
    "    \n",
    "    Parameters:\n",
    "    n (int): The size of the grid\n",
    "    grid (np.ndarray): The grid of the sandpile\n",
    "    history (list): A list of the sandpile grids at each timestep\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n=100, random_state=None):\n",
    "        self.n = n\n",
    "        np.random.seed(random_state) # Set the random seed\n",
    "        self.grid = np.random.choice([0, 1, 2, 3], size=(n, n))\n",
    "        self.history =[self.grid.copy()] # Why did we need to copy the grid?\n",
    "        self.sites_to_check = [] #an array of sites that we need to loop through in the \n",
    "        #cascade. \n",
    "\n",
    "\n",
    "        \n",
    "    def cascade(self):\n",
    "        \"\"\"\n",
    "        This function checks whether the site at i_index, j_index needs to topple. If it does\n",
    "        it topples the pile, sending grains to it's viable neighbours (obeying the absorbing BCs)\n",
    "        and adding those neighbours to the list of sites to check (sites_to_check). It then removes\n",
    "        the first element of the sites_to_check array, as that was the point that started the cascade. \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        while len(self.sites_to_check) != 0: #as long as there are sites to check.\n",
    "            for site in self.sites_to_check:\n",
    "                if self.grid[site[0], site[1]] < 4:\n",
    "                    self.sites_to_check = self.sites_to_check[1:] #cutting off the site\n",
    "                else:\n",
    "                    self.grid[site[0], site[1]] -= 4 #toppling.\n",
    "                    #sending sandgrains to the surronding piles, but respecting BCs. \n",
    "                    if site[0] > 0:\n",
    "                        self.grid[site[0]-1, site[1]] += 1\n",
    "                        self.sites_to_check.append([site[0]-1, site[1]])\n",
    "                    if site[0] < (self.n-1):\n",
    "                        self.grid[site[0]+1, site[1]] += 1\n",
    "                        self.sites_to_check.append([site[0]+1, site[1]])\n",
    "                    if site[1] > 0:\n",
    "                        self.grid[site[0], site[1]-1] += 1\n",
    "                        self.sites_to_check.append([site[0], site[1]-1])\n",
    "                    if site[1] < (self.n-1):\n",
    "                        self.grid[site[0], site[1]+1] += 1\n",
    "                        self.sites_to_check.append([site[0], site[1]+1])\n",
    "                    self.sites_to_check = self.sites_to_check[1:]\n",
    "                        \n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Perform a single step of the sandpile model. Step corresponds a single sandgrain \n",
    "        addition and the consequent toppling it causes. \n",
    "\n",
    "        Returns: None\n",
    "        \"\"\"\n",
    "        \n",
    "        ########## YOUR CODE HERE ##########\n",
    "        #\n",
    "        #To get my code to reproduce Gilpin's distributions, I had to use the following\n",
    "        #line from his solutions to get the exact same ICs. Apologies. I include below\n",
    "        #how I initially did it, which works but produces a slightly different set of ICs. \n",
    "        new_sand_x, new_sand_y = np.random.choice(self.n, 2)\n",
    "        \n",
    "        \n",
    "        #Adding a grain of sand somewhere on the grid at random. \n",
    "        #new_sand_x = np.random.randint(0, self.n - 1)\n",
    "        #new_sand_y = np.random.randint(0, self.n - 1)\n",
    "        \n",
    "        self.grid[new_sand_x, new_sand_y] += 1\n",
    "        self.sites_to_check.append([new_sand_x, new_sand_y])\n",
    "        \n",
    "        self.cascade()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        ########## YOUR CODE HERE ##########\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    # we use this decorator for class methods that don't require any of the attributes \n",
    "    # stored in self. Notice how we don't pass self to the method\n",
    "    @staticmethod\n",
    "    def check_difference(grid1, grid2):\n",
    "        \"\"\"Check the total number of different sites between two grids\"\"\"\n",
    "        return np.sum(grid1 != grid2)\n",
    "\n",
    "    \n",
    "    def simulate(self, n_step):\n",
    "        \"\"\"\n",
    "        Simulate the sandpile model for n_step steps.\n",
    "        \"\"\"\n",
    "        ########## YOUR CODE HERE ##########\n",
    "\n",
    "\n",
    "        for n in range(0, n_step):\n",
    "            self.step()\n",
    "            if n%1000 == 0:\n",
    "                print(\"made it to step: \" + str(n))\n",
    "            if self.check_difference(self.grid, self.history[-1]) > 0:\n",
    "                self.history.append(self.grid.copy())\n",
    "        \n",
    "        return(self.grid)\n",
    "        #\n",
    "        #\n",
    "        # YOUR CODE HERE. You should use the step method you wrote above.\n",
    "        #\n",
    "        #\n",
    "        ########## YOUR CODE HERE ##########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8071e4",
   "metadata": {},
   "source": [
    "### Test and use your code\n",
    "\n",
    "+ You don't need to write any code below, these cells are just to confirm that everything is working and to play with your sandpile implementation\n",
    "+ If you are working from a local fork of the entire course, then you already have access to the solutions. In this case, make sure to `git pull` to make sure that you are up-to-date (save your work first).\n",
    "+ If you are working from a single downloaded notebook, or are working in Google Colab, then you will need to manually download the solutions file from the course repository. The lines below will do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc85fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the \"solutions\" directory exists. If not, create it and download the solution file\n",
    "import os\n",
    "if not os.path.exists('solutions'):\n",
    "    os.makedirs('solutions')\n",
    "else:\n",
    "    print('Directory \"solutions\" already exists. Skipping creation.')\n",
    "!wget -P solutions https://raw.githubusercontent.com/williamgilpin/cphy/main/hw/solutions/sandpile.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25237ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import William's solution from answer key\n",
    "# from solutions.sandpile import AbelianSandpile\n",
    "# from solutions.sandpile import AbelianSandpileBFS as AbelianSandpile\n",
    "# from solutions.sandpile import AbelianSandpileDFS as AbelianSandpile\n",
    "\n",
    "\n",
    "# Run sandpile simulation\n",
    "import scipy.optimize\n",
    "def sandpile_fit(T, alpha, beta):\n",
    "    \"\"\"Just a function that I'll fit to later. \n",
    "\n",
    "    Args:\n",
    "        T (int): The waiting time. \n",
    "        alpha (float): exponent in the timescale model. \n",
    "        beta (float): A normalisation factor. \n",
    "    \"\"\"\n",
    "    return(beta/(T**alpha))\n",
    "\n",
    "\n",
    "model = AbelianSandpile(n=100, random_state=0)\n",
    "\n",
    "initial_state = model.grid\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(model.grid, cmap='gray')\n",
    "plt.title(\"Initial State\")\n",
    "\n",
    "model.simulate(10000)\n",
    "plt.figure()\n",
    "plt.imshow(model.grid, cmap='gray')\n",
    "plt.title(\"Final state\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute the pairwise difference between all observed snapshots. This command uses list\n",
    "# comprehension, a zip generator, and argument unpacking in order to perform this task\n",
    "# concisely.\n",
    "all_events =  [model.check_difference(*states) for states in zip(model.history[:-1], model.history[1:])]\n",
    "# remove transients before the self-organized critical state is reached\n",
    "all_events = all_events[1000:]\n",
    "# index each timestep by timepoint\n",
    "all_events = list(enumerate(all_events))\n",
    "# remove cases where an avalanche did not occur\n",
    "all_avalanches = [x for x in all_events if x[1] > 1]\n",
    "all_avalanche_times = [item[0] for item in all_avalanches]\n",
    "all_avalanche_sizes = [item[1] for item in all_avalanches]\n",
    "all_avalanche_durations = [event1 - event0 for event0, event1 in zip(all_avalanche_times[:-1], all_avalanche_times[1:])]\n",
    "\n",
    "\n",
    "## Waiting time distribution\n",
    "waiting_times = np.diff(np.array(all_avalanche_times))\n",
    "plt.figure()\n",
    "plt.semilogy()\n",
    "plt.hist(waiting_times)\n",
    "plt.title('Waiting Time distribution')\n",
    "plt.xlabel('Waiting time')\n",
    "plt.ylabel('Number of events')\n",
    "\n",
    "## Duration distribution\n",
    "log_bins = np.logspace(np.log10(2), np.log10(np.max(all_avalanche_durations)), 50) # logarithmic bins for histogram\n",
    "vals, bins = np.histogram(all_avalanche_durations, bins=log_bins)\n",
    "\n",
    "\n",
    "\n",
    "## Writing some code to fit T^(-\\alpha) to the data\n",
    "#first filtering out the zeros in the vals:\n",
    "zeros_stencil = (vals != 0)\n",
    "bins_minus_end = np.copy(bins[:-1])\n",
    "vals_to_fit = vals[zeros_stencil]\n",
    "bins_to_fit = bins_minus_end[zeros_stencil]\n",
    "\n",
    "\n",
    "    \n",
    "fit_coeffs, fit_covars = scipy.optimize.curve_fit(sandpile_fit, bins_to_fit, vals_to_fit, p0=[1.1, 1000])\n",
    "fitted_vals = [sandpile_fit(T, fit_coeffs[0], fit_coeffs[1]) for T in bins_to_fit]\n",
    "\n",
    "\n",
    "print(fit_coeffs)\n",
    "print(fit_covars)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.loglog(bins[:-1], vals, '.', markersize=10)\n",
    "plt.loglog(bins_to_fit, fitted_vals, 'xr', markersize=10)\n",
    "plt.title('Avalanche duration distribution')\n",
    "plt.xlabel('Avalanche duration')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "## Visualize activity of the avalanches\n",
    "# Make an array storing all pairwise differences between the lattice at successive\n",
    "# timepoints\n",
    "all_diffs = np.abs(np.diff(np.array(model.history), axis=0))\n",
    "all_diffs[all_diffs > 0] = 1\n",
    "all_diffs = all_diffs[np.sum(all_diffs, axis=(1, 2)) > 1] # Filter to only keep big events\n",
    "most_recent_events = np.sum(all_diffs[-100:], axis=0)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(most_recent_events)\n",
    "plt.title(\"Avalanche activity in most recent timesteps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the experimental calculation of run-time scaling. This is ugly and dumb, but it works. \n",
    "import timeit\n",
    "\n",
    "n_to_test = np.arange(1, 1000, 5)\n",
    "time_taken = []\n",
    "for n_points in n_to_test:\n",
    "    time_taken.append(timeit.timeit(\"AbelianSandpile(n=n_points, random_state=0)\", globals=globals(), number = 10))\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(n_to_test, time_taken)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602244e",
   "metadata": {},
   "source": [
    "# My Attempt at Vectorisation\n",
    "Below is my attempt at vectorising the sandpile simulation. For the life of me I don't undestand why it doesn't produce the exact same final state... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a3b5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbelianSandpileVectorised: \n",
    "    \"\"\"\n",
    "    An Abelian sandpile model simulation. The sandpile is initialized with a random\n",
    "    number of grains at each lattice site. Then, a single grain is dropped at a random\n",
    "    location. The sandpile is then allowed to evolve until it is stable. This process\n",
    "    is repeated n_step times.\n",
    "\n",
    "    A single step of the simulation consists of two stages: a random sand grain is \n",
    "    dropped onto the lattice at a random location. Then, a set of avalanches occurs\n",
    "    causing sandgrains to get redistributed to their neighboring locations.\n",
    "    \n",
    "    Parameters:\n",
    "    n (int): The size of the grid\n",
    "    grid (np.ndarray): The grid of the sandpile\n",
    "    history (list): A list of the sandpile grids at each timestep\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n=100, random_state=None):\n",
    "        self.n = n\n",
    "        np.random.seed(random_state) # Set the random seed\n",
    "        self.grid = np.random.choice([0, 1, 2, 3], size=(n, n))\n",
    "        self.history =[self.grid.copy()] # Why did we need to copy the grid?\n",
    "\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Perform a single step of the sandpile model. Step corresponds a single sandgrain \n",
    "        addition and the consequent toppling it causes. \n",
    "\n",
    "        Returns: None\n",
    "        \"\"\"\n",
    "        \n",
    "        ########## YOUR CODE HERE ##########\n",
    "        #\n",
    "        #\n",
    "        # My solution starts by dropping a grain, and then solving for all topple events \n",
    "        # until the sandpile is stable. Watch your boundary conditions carefully.\n",
    "        # We will use absorbing boundary conditions: excess sand grains fall off the edges\n",
    "        # of the grid.\n",
    "        \n",
    "        #Adding a grain of sand somewhere on the grid at random. To get my code to reproduce Gilpin's distributions, \n",
    "        # I had to use the following line from his solutions to get the exact same ICs. Apologies. I initially just used\n",
    "        #new_sand_x = np.random.randint(0, self.n - 1)\n",
    "        #new_sand_y = np.random.randint(0, self.n - 1)\n",
    "        #which works but produces a slightly different set of ICs. \n",
    "        \n",
    "        new_sand_x, new_sand_y = np.random.choice(self.n, 2)\n",
    "        self.grid[new_sand_y, new_sand_x] += 1\n",
    "        \n",
    "        #Now that we have added some sand to the grid, we have to check whether it caused any topples.\n",
    "\n",
    "\n",
    "        piles_to_topple = (self.grid >= 4)\n",
    "                \n",
    "        while np.any(piles_to_topple) == True:\n",
    "            #removing the piles that are 4 or taller. \n",
    "            self.grid[piles_to_topple] -= 4\n",
    "            \n",
    "            #we make a new array with an extra space around the rim. That way we can add sand to each \n",
    "            #space around the toppled piles, then slice away the edges of the grid when we are done. \n",
    "            expanded_grid = np.zeros((self.n+2, self.n+2))\n",
    "            expanded_grid[1:-1, 1:-1] = self.grid\n",
    "        \n",
    "             \n",
    "            #building the stencils to tell me where to add grains. \n",
    "            stencil_shifted_up = np.vstack((piles_to_topple, np.zeros((1, self.n), dtype = bool)))\n",
    "            stencil_shifted_up = np.vstack((stencil_shifted_up, np.zeros((1, self.n), dtype = bool)))\n",
    "            stencil_shifted_up = np.hstack((stencil_shifted_up, np.zeros((self.n + 2, 1), dtype = bool))) \n",
    "            stencil_shifted_up = np.hstack((np.zeros((self.n + 2, 1), dtype = bool), stencil_shifted_up))\n",
    "             \n",
    "            \n",
    "            stencil_shifted_down = np.vstack((np.zeros((1, self.n), dtype = bool), piles_to_topple))\n",
    "            stencil_shifted_down = np.vstack((np.zeros((1, self.n), dtype = bool), stencil_shifted_down))\n",
    "            stencil_shifted_down = np.hstack((stencil_shifted_down, np.zeros((self.n + 2, 1), dtype = bool)))\n",
    "            stencil_shifted_down = np.hstack((np.zeros((self.n + 2, 1), dtype = bool), stencil_shifted_down))\n",
    "            \n",
    "            \n",
    "            stencil_shifted_left = np.hstack((piles_to_topple, np.zeros((self.n, 1), dtype = bool)))\n",
    "            stencil_shifted_left = np.hstack((stencil_shifted_left, np.zeros((self.n, 1), dtype = bool)))\n",
    "            stencil_shifted_left = np.vstack((stencil_shifted_left, np.zeros((1, self.n + 2), dtype = bool)))\n",
    "            stencil_shifted_left = np.vstack((np.zeros((1, self.n + 2), dtype = bool), stencil_shifted_left))\n",
    "            \n",
    "            \n",
    "            stencil_shifted_right = np.hstack((np.zeros((self.n, 1), dtype = bool), piles_to_topple))\n",
    "            stencil_shifted_right = np.hstack((np.zeros((self.n, 1), dtype = bool), stencil_shifted_right))\n",
    "            stencil_shifted_right = np.vstack((stencil_shifted_right, np.zeros((1, self.n + 2), dtype = bool)))\n",
    "            stencil_shifted_right = np.vstack((np.zeros((1, self.n + 2), dtype = bool), stencil_shifted_right))\n",
    "            \n",
    "            expanded_grid[stencil_shifted_down] += 1\n",
    "            expanded_grid[stencil_shifted_left] += 1\n",
    "            expanded_grid[stencil_shifted_right] += 1\n",
    "            expanded_grid[stencil_shifted_up] += 1\n",
    "            \n",
    "            self.grid = expanded_grid[1:-1, 1:-1]\n",
    "            piles_to_topple = (self.grid >= 4) #checking to see if there are any more piles to topple. \n",
    "        \n",
    "        ########## YOUR CODE HERE ##########\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    # we use this decorator for class methods that don't require any of the attributes \n",
    "    # stored in self. Notice how we don't pass self to the method\n",
    "    @staticmethod\n",
    "    def check_difference(grid1, grid2):\n",
    "        \"\"\"Check the total number of different sites between two grids\"\"\"\n",
    "        return np.sum(grid1 != grid2)\n",
    "\n",
    "    \n",
    "    def simulate(self, n_step):\n",
    "        \"\"\"\n",
    "        Simulate the sandpile model for n_step steps.\n",
    "        \"\"\"\n",
    "        ########## YOUR CODE HERE ##########\n",
    "\n",
    "\n",
    "        for n in range(0, n_step):\n",
    "            self.step()\n",
    "            if n%1000 == 0:\n",
    "                print(\"made it to step: \" + str(n))\n",
    "            if self.check_difference(self.grid, self.history[-1]) > 0:\n",
    "                self.history.append(self.grid.copy())\n",
    "        \n",
    "        return(self.grid)\n",
    "        #\n",
    "        #\n",
    "        # YOUR CODE HERE. You should use the step method you wrote above.\n",
    "        #\n",
    "        #\n",
    "        ########## YOUR CODE HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2556633",
   "metadata": {},
   "source": [
    "\n",
    "### Additional information and follow-up\n",
    "\n",
    "+ Another member of our department, Michael Marder, has a [paper from 1992 in which he and his student Steve Kramer propose a cellular automaton model of river formation.](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.68.205) (Figure 2 is gorgeous!). The update rules and structure of implementing this simulation have many simularities to the BTK model, but, unlike the BTK model, there are not any open-source implementations of which I am aware.\n",
    "+ Among cellular automata, the BTW model is not only unique for its asynchronous nature, but also because it has a \"derivative\" ruleset in contrast to the \"integral\"/totalistic ruleset we see in better-known systems like the Game of Life: instead of updating a cell based on the sum of all its neighbors, we update all neighbors based on the state of a cell.\n",
    "+ The BTK model is called the \"Abelian\" sandpile because the final stable configuration is invariant to the order of toppling events. For example, instead of toppling the pile to completion after each addition, we could add $M$ several grains at once, and then perform a series of topples selecting unstable sites in any order until a stable configuration is achieved. The final sandpile would be identical to the one we would get if we simulated the pile through $M$ full additions sequentially.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2b3764",
   "metadata": {},
   "source": [
    "### Extra  code for animations\n",
    "+ No need to run this, but this code allows you to visualize the sandpile as it evolves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "activity_sliding2 = all_diffs[-500:]\n",
    "vmin = np.percentile(activity_sliding2, 1)\n",
    "# vmin = 0\n",
    "vmax = np.percentile(activity_sliding2, 99.8)\n",
    "\n",
    "# Assuming frames is a numpy array with shape (num_frames, height, width)\n",
    "frames = np.array(activity_sliding2).copy() \n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "img = plt.imshow(frames[0], vmin=vmin, vmax=vmax);\n",
    "plt.xticks([]); plt.yticks([])\n",
    "# tight margins\n",
    "plt.margins(0,0)\n",
    "plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "def update(frame):\n",
    "    img.set_array(frame)\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=frames, interval=50)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_diffs = np.abs(np.diff(np.array(model.history), axis=0))\n",
    "# all_diffs = all_diffs[np.sum(all_diffs, axis=(1, 2)) > 1] # Filter to only keep big events\n",
    "\n",
    "# Use a trick to calculate the sliding cumulative sum\n",
    "activity_cumulative = np.cumsum(all_diffs, axis=0)\n",
    "# activity_sliding = activity_cumulative[50:] - activity_cumulative[:-50]\n",
    "activity_sliding = all_diffs\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(activity_sliding[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fab54",
   "metadata": {},
   "source": [
    "I don't understand why this cell doesn't run, but it just makes the movie? I am going to comment it out for now so the rest can go ahead and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb80419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# This code saves the sliding cumulative sum as a movie. No need to run this cell\n",
    "\n",
    "\n",
    "activity_sliding2 = activity_sliding[-500:]\n",
    "vmin = np.percentile(activity_sliding2, 1)\n",
    "# vmin = 0\n",
    "vmax = np.percentile(activity_sliding2, 99.8)\n",
    "for i in range(len(activity_sliding2) - 1):\n",
    "    \n",
    "    out_path = \"private_dump/sandpile/frame\" + str(i).zfill(4) + \".png\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(activity_sliding2[i], vmin=vmin, vmax=vmax)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.set_aspect(1, adjustable='box')\n",
    "\n",
    "    plt.savefig(out_path, bbox_inches='tight', pad_inches=0.0, dpi=300)\n",
    "    plt.close() \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdfac94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5bcb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4618add6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d4a9454",
   "metadata": {},
   "source": [
    "# Percolation\n",
    "\n",
    "The BTK cellular automaton represents a great example of a simple, toy computational model that exhibits non-trivial properties found in other, much more elaborate problems. It can be considered a [dynamical universality class](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.72.1690), meaning that many problems map onto it, independently of their microscopic details.\n",
    "\n",
    "Here, we will consider a well-known example of a universality class describing a nonequilibrium phase transition: the directed percolation problem. This problem is usually attributed to [Broadbent & Hammersley in 1957](https://www.cambridge.org/core/journals/mathematical-proceedings-of-the-cambridge-philosophical-society/article/percolation-processes/C00CC4943F48228F8AC8031092FE84EC).\n",
    "\n",
    "The basic idea is deceptively simple: given a D-dimensional lattice (for our purposes, a 2D grid), we randomly mark sites as \"blocked\" with probability $p$. The remaining sites are \"open\" for water to flow. For a given value of $p$, what is the probability that water poured into the top of the lattice will percolate to the bottom row through a chain of connected open sites? This problem is *directed percolation* because it has a preferred direction (water flows from top to bottom). We will assume two open sites are connected if one is north, south, east, or west of the other---but *not* diagonal. This corresponds to [von Neumann neighborhood rules](https://en.wikipedia.org/wiki/Von_Neumann_neighborhood).\n",
    "\n",
    "A percolation simulation should take a binary array, and return True if it percolates, and False if it does not. There are many ways to implement a percolation algorithm, most of which involve simulating the addition of water to the grid. \n",
    "+ *Iterative Solution.* One option would be start with the top row, mark all open sites as \"filled,\" and then pass to the next row and search for open sites connected to filled sites. Some addtional care is required, however, because water can pass through channels within a row until it reaches sites that are not directly below filled sites. One workaround would be to perform multiple iterative passes until the filled lattice stops changing. Another edge case is the case where water needs to pass through an uphill channel in order to make it to the bottom---this can be solved by passing over the lattice first from top to bottom, and then vice versa.\n",
    "+ *Depth-first search (DFS).* Another simulation option would be a depth-first-search, where we start from each site on the top row and we search for any chain of North/Sout/East/West hops that leads to the other side of the lattice, marking all visited sites as filled with water. This last methods demonstrates the conceptual simularity between directed percolation and solving a maze puzzle; the only difference that the \"blocked\" sites in a maze are non-random. \n",
    "\n",
    "Here we are going to implemented a directed percolation model, and then perform experiments with it in order to determine how the percolation probability depends on the fraction of blocked sites $p$.\n",
    "\n",
    "## To Do\n",
    "\n",
    "1. Implement a two dimensional directed percolation model in Python. I've included my code outline below.\n",
    "    + The iterative solution simulates water pouring into the top row, and then iterate over rows and sites. With this solution, there is some difficulty regarding how to handle the case where water can flow through a channel from right to left, even though we normally iterate from left to right. This can be solved by passing over each row twice. However, there is also a the case where water needs to pass uphill through a channel before it can proceed downhill. This can be solved by passing over the lattice from top to bottom, and then vice versa.\n",
    "    + Can you think of a faster way of solving this problem? (Hint: we may not have seen recursion in class yet, but it may be helpful). If you want to try implementing your solution, you will need to add an additional private method `_flow_recursive(i, j)` that contains the recursive logic\n",
    "2. Perform replicate simulations using the code I've provided below, and create a plot showing how the probability of percolation changes as a function of $p$ (the blockage probability). Beyond seeing the percolation to clogging transition, you'll notice that the variance in the outcome of your simulations behaves unexpectedly. What is going on here? (Hint: If you've studied the Ising model, you've seen something like this before)\n",
    "3. Theoretically, does the transition point seen in our empirical results align with your intuition? Why does its value differ from $p=0.5$? (Hint: think about sites versus connections between sites).\n",
    "4. How does the memory usage and runtime of your percolation model implement scale with the lattice size? You can answer this empirically or theoretically.\n",
    "5. One way to sweep the control parameter $p$ would be to start in a limit where most of the sites are blocked, and then gradually open up individual sites one at a time until the lattice percolates. A video of a simulation where the lattice is gradually opened can be seen [here](https://vimeo.com/747772333). How do the different events in this gradually unblocked percolation simulation relate to the two timescales we saw in the sandpile problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52be492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e1d86ad",
   "metadata": {},
   "source": [
    "# My Answers to the Percolation Questions. \n",
    "\n",
    "1. Using a very similar method to how I solved the sandpile simulation, I implemented what I think qualifies as a recursive solution to the percolation problem. I use\n",
    "a function called \"waterfall\" to do a depth first search through the maze. Percolation just calles that waterfall function. I wound up not using the \"poll_neighbours\" function.\n",
    "\n",
    "2. By \"behaves unexpectedly\" do you mean the variance has finite width? I have studied the Ising model a little bit, but I am having trouble seeing a complete connection here, as here the connected regions have no energetic reason to want to connect/disconnect. I almost want to say this is like the formation of Peierls droplets, but that requires that certain spin orientations have lower energy than others, which is where the analogy falls apart. \n",
    "\n",
    "    My best guess (but it really is a wild guess) is that there is a sharp phase transition between clogged and unclogged, but that before this point there is still the possibilty for the grid to be clogged, and after the transition there is still a chance for the grid to be unclogged. \n",
    "\n",
    "3. I would have thought the transition would be at $p = 0.5$, but it appears to happen a bit earlier than that at $p \\sim 0.4$. For water to flow, you need two sites to be connected, so you actually need $p$ to be less than $0.5$ for there to be a better than even chance of a connection forming. Thus the transition would actually occur somewhere before $p = 0.5$.\n",
    "\n",
    "4. As in the sandpile simulation, since we are storing an $N\\times N$ grid, the memory scaling should go like $N^2$. As I am more or less implementing the same algorithm as in the sandpile problem, I expect the runtime complexity to also scale like $N^2$. I include some code below to experimentally verify this, which it does. \n",
    "\n",
    "5. The point at which the grid suddenly allows water to flow is similar to the transition out of the quiescent (when the sand isn't evenly distributed so we have localised avalanches more frequently) period in the sandpile simulation, to the catastrophic largescale collapse we saw as a bump in the sandpile waiting time distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec4ba2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PercolationSimulation:\n",
    "    \"\"\"\n",
    "    A simulation of a 2D directed percolation problem. Given a 2D lattice, blocked sites\n",
    "    are denoted by 0s, and open sites are denoted by 1s. During a simulation, water is\n",
    "    poured into the top of the grid, and allowed to percolate to the bottom. If water\n",
    "    fills a lattice site, it is marked with a 2 in the grid. Water only reaches a site\n",
    "    if it reaches an open site directly above, or to the immediate left or right \n",
    "    of an open site.\n",
    "\n",
    "    I've included the API for my solution below. You can use this as a starting point, \n",
    "    or you can re-factor the code to your own style. Your final solution must have a \n",
    "    method called percolate that creates a random lattice and runs a percolation \n",
    "    simulation and\n",
    "    1. returns True if the system percolates\n",
    "    2. stores the original lattice in self.grid\n",
    "    3. stores the water filled lattice in self.grid_filled\n",
    "\n",
    "    + For simplicity, use the first dimension of the array as the percolation direction\n",
    "    + For boundary conditions, assume that any site out of bounds is a 0 (blocked)\n",
    "    + You should use numpy for this problem, although it is possible to use lists \n",
    "\n",
    "\n",
    "\n",
    "    Attributes:\n",
    "        grid (np.array): the original lattice of blocked (0) and open (1) sites\n",
    "        grid_filled (np.array): the lattice after water has been poured in\n",
    "        n (int): number of rows and columns in the lattice\n",
    "        p (float): probability of a site being blocked in the randomly-sampled lattice\n",
    "            random_state (int): random seed for the random number generator\n",
    "        random_state (int): random seed for numpy's random number generator. Used to \n",
    "            ensure reproducibility across random simulations. The default value of None\n",
    "            will use the current state of the random number generator without resetting\n",
    "            it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n=100, p=0.5, grid=None, random_state=None):\n",
    "        \"\"\"\n",
    "        Initialize a PercolationSimulation object.\n",
    "\n",
    "        Args:\n",
    "            n (int): number of rows and columns in the lattice\n",
    "            p (float): probability of a site being blocked in the randomly-sampled lattice\n",
    "            random_state (int): random seed for numpy's random number generator. Used to\n",
    "                ensure reproducibility across random simulations. The default value of None\n",
    "                will use the current state of the random number generator without resetting\n",
    "                it.\n",
    "        \"\"\"\n",
    "\n",
    "        self.random_state = random_state # the random seed\n",
    "\n",
    "        # Initialize a random grid if one is not provided. Otherwise, use the provided\n",
    "        # grid.\n",
    "        if grid is None:\n",
    "            self.n = n\n",
    "            self.p = p\n",
    "            self.grid = np.zeros((n, n))\n",
    "            self._initialize_grid()\n",
    "        else:\n",
    "            assert len(np.unique(np.ravel(grid))) <= 2, \"Grid must only contain 0s and 1s\"\n",
    "            self.grid = grid.astype(int)\n",
    "            # override numbers if grid is provided\n",
    "            self.n = grid.shape[0]\n",
    "            self.p = 1 - np.mean(grid)\n",
    "\n",
    "        # The filled grid used in the percolation calculation. Initialize to the original\n",
    "        # grid. We technically don't need to copy the original grid if we want to save\n",
    "        # memory, but it makes the code easier to debug if this is a separate variable \n",
    "        # from self.grid.\n",
    "        self.grid_filled = np.copy(self.grid)\n",
    "        self.sites_to_check = []\n",
    "\n",
    "    def _initialize_grid(self):\n",
    "        \"\"\"\n",
    "        Sample a random lattice for the percolation simulation. This method should\n",
    "        write new values to the self.grid and self.grid_filled attributes. Make sure\n",
    "        to set the random seed inside this method.\n",
    "\n",
    "        This is a helper function for the percolation algorithm, and so we denote it \n",
    "        with an underscore in order to indicate that it is not a public method (it is \n",
    "        used internally by the class, but end users should not call it). In other \n",
    "        languages like Java, private methods are not accessible outside the class, but\n",
    "        in Python, they are accessible but external usage is discouraged by convention.\n",
    "\n",
    "        Private methods are useful for functions that are necessary to support the \n",
    "        public methods (here, our percolate() method), but which we expect we might need\n",
    "        to alter in the future. If we released our code as a library, others might \n",
    "        build software that accesses percolate(), and so we should not alter the \n",
    "        input/outputs because it's a public method\n",
    "        \"\"\"\n",
    "        ###############################################################################\n",
    "        \n",
    "        #\n",
    "        ####### YOUR CODE HERE  ####### \n",
    "\n",
    "        \"\"\"\n",
    "        np.random.seed(self.random_state)\n",
    "        self.grid = np.random.choice([0, 1], size=(self.n, self.n), p=[self.p, 1-self.p])\n",
    "        self.grid_filled = np.copy(self.grid)\n",
    "        \"\"\"\n",
    "        \n",
    "        #Gilpin's code for the initialisation, necessary to get the same ICs.\n",
    "        np.random.seed(self.random_state)\n",
    "        self.grid = np.random.choice([1, 0], size=(self.n, self.n), p=[1-self.p, self.p])\n",
    "        self.grid_filled = np.copy(self.grid)\n",
    "        \n",
    "        # Hint: my solution is 3 lines of code in numpy\n",
    "        #\n",
    "        #\n",
    "        ###############################################################################\n",
    "        \n",
    "\n",
    "    def _flow_recursive(self, i, j):\n",
    "        \"\"\"\n",
    "        Only used if we opt for a recursive solution.\n",
    "\n",
    "        The recursive portion of the flow simulation. Notice how grid and grid_filled\n",
    "        are used to keep track of the global state, even as our recursive calls nest\n",
    "        deeper and deeper\n",
    "        \"\"\"\n",
    "        \n",
    "        ####### YOUR CODE HERE  #######################################################\n",
    "        #\n",
    "        # Remember to check the von Neumann neighborhood of the current site. There should\n",
    "        # be 4 recursive calls in total, and 4 base cases\n",
    "        #\n",
    "        #\n",
    "        ###############################################################################s\n",
    "\n",
    "\n",
    "    def _poll_neighbors(self, i, j):\n",
    "        \"\"\"\n",
    "        Check whether there is a filled site adjacent to a site at coordinates i, j in \n",
    "        self.grid_filled. Respects boundary conditions.\n",
    "        \"\"\"\n",
    "\n",
    "        ####### YOUR CODE HERE  #######################################################\n",
    "        # Hint: my solution is 4 lines of code in numpy, but you may get different \n",
    "        # results depending on how you enforce the boundary conditions in your solution.\n",
    "        # Not needed for the recursive solution\n",
    "        #\n",
    "        #\n",
    "        ###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "    def _flow(self):\n",
    "        \"\"\"\n",
    "        Run a percolation simulation using recursion\n",
    "\n",
    "        This method writes to the grid and grid_filled attributes, but it does not\n",
    "        return anything. In other languages like Java or C, this method would return\n",
    "        void\n",
    "        \"\"\"\n",
    "        ###############################################################################\n",
    "        raise NotImplementedError(\"Implement this method\")\n",
    "        ####### YOUR CODE HERE  ####### \n",
    "        # Hint: my non-recursive solution contains one row-wise for loop, which contains \n",
    "        # several loops over individual lattice sites. You might need to visit each lattice \n",
    "        # site more than once per row. In my implementation, split the logic of checking\n",
    "        # the von neumann neighborhood into a separate method _poll_neighbors, which\n",
    "        # returns a boolean indicating whether a neighbor is filled\n",
    "        #\n",
    "        # My recursive solution calls a second function, _flow_recursive, which takes \n",
    "        # two lattice indices as arguments\n",
    "\n",
    "        ###############################################################################\n",
    "\n",
    "    def waterfall(self):\n",
    "        \"\"\"\n",
    "        This function checks whether the site at i_index, j_index has open (no water and not blocked) neighbours, \n",
    "        and is open itself. If it does, and is full of water itself, it sends water to it's viable neighbours, and \n",
    "        adds those neighbours to the list of sites to check (sites_to_check). It then removes itself\n",
    "        (the first element of the sites_to_check array). \n",
    "        \n",
    "        \"\"\"\n",
    "        while len(self.sites_to_check) != 0: #as long as there are sites to check.\n",
    "            for site in self.sites_to_check:\n",
    "                if site[1] < self.n-1:\n",
    "                    if (self.grid_filled[site[0], site[1] + 1] == 1):\n",
    "                        self.grid_filled[site[0], site[1] + 1] = 2\n",
    "                        self.sites_to_check.append([site[0], site[1] + 1])\n",
    "                if site[1] > 0:\n",
    "                    if (self.grid_filled[site[0], site[1] - 1] == 1):\n",
    "                        self.grid_filled[site[0], site[1] - 1] = 2\n",
    "                        self.sites_to_check.append([site[0], site[1] - 1])\n",
    "                if site[0] < self.n-1:\n",
    "                    if (self.grid_filled[site[0] + 1, site[1]] == 1):\n",
    "                        self.grid_filled[site[0] + 1, site[1]] = 2\n",
    "                        self.sites_to_check.append([site[0] + 1, site[1]])\n",
    "                if site[0] > 0:\n",
    "                    if (self.grid_filled[site[0] - 1, site[1]] == 1):\n",
    "                        self.grid_filled[site[0] - 1, site[1]] = 2\n",
    "                        self.sites_to_check.append([site[0] - 1, site[1]])\n",
    "                self.sites_to_check = self.sites_to_check[1:] #we've checked the neighbours, so we can remove the grid point.\n",
    "\n",
    "\n",
    "    def percolate(self):\n",
    "        \"\"\"\n",
    "        Initialize a random lattice and then run a percolation simulation. Report results\n",
    "        \"\"\"\n",
    "        ###############################################################################\n",
    "\n",
    "        ####### YOUR CODE HERE  #######     \n",
    "        \n",
    "        \n",
    "        #I start off by adding zeros around the edges of the array so that I don't have to \n",
    "        #manually account for the boundary conditions with a whole mess of if statements. \n",
    "        self._initialize_grid()\n",
    "        \n",
    "        #doing the first row scan to make sure we don't have a capped off sponge, which would crash my _poll_neighbours\n",
    "        #function. I'm sure you could vectorise this, but I have covid and can't think too well at the moment. \n",
    "        \n",
    "        for j in range(0, self.n):\n",
    "            if self.grid_filled[0, j] == 1:\n",
    "                self.grid_filled[0, j] = 2\n",
    "                self.sites_to_check.append([0, j])\n",
    "\n",
    "\n",
    "        self.waterfall()\n",
    "        \n",
    "        if np.any(self.grid_filled[-1, :] == 2):\n",
    "            return(True)\n",
    "        else:\n",
    "            return(False)      \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Hint: my solution is 3 lines of code, and it just calls other methods in the\n",
    "        # class, which do the heavy lifting\n",
    "\n",
    "        ###############################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c115456",
   "metadata": {},
   "source": [
    "### Test and use your code\n",
    "\n",
    "+ You don't need to write any new code below, these cells are just to confirm that everything is working and to play with the your percolation implementation\n",
    "+ If you are working from a local fork of the entire course, then you already have access to the solutions. In this case, make sure to `git pull` to make sure that you are up-to-date (save your work first).\n",
    "+ If you are working from a single downloaded notebook, or are working in Google Colab, then you will need to manually download the solutions file from the course repository. The lines below will do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the \"solutions\" directory exists. If not, create it and download the solution file\n",
    "import os\n",
    "if not os.path.exists('solutions'):\n",
    "    os.makedirs('solutions')\n",
    "else:\n",
    "    print('Directory \"solutions\" already exists. Skipping creation.')\n",
    "!wget -P solutions https://raw.githubusercontent.com/williamgilpin/cphy/main/hw/solutions/percolation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53214e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import William's solution\n",
    "# from solutions.percolation import PercolationSimulation\n",
    "# from solutions.percolation_iterative import PercolationSimulation\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "def plot_percolation(mat):\n",
    "    \"\"\"\n",
    "    Plots a percolation matrix, where 0 indicates a blocked site, 1 indicates an empty \n",
    "    site, and 2 indicates a filled site\n",
    "    \"\"\"\n",
    "    cvals  = [0, 1, 2]\n",
    "    colors = [(0, 0, 0), (0.4, 0.4, 0.4), (0.372549, 0.596078, 1)]\n",
    "\n",
    "    norm = plt.Normalize(min(cvals), max(cvals))\n",
    "    tuples = list(zip(map(norm,cvals), colors))\n",
    "    cmap = LinearSegmentedColormap.from_list(\"\", tuples)\n",
    "    plt.imshow(mat, cmap=cmap, vmin=0, vmax=2)\n",
    "#20\n",
    "\n",
    "model = PercolationSimulation(n=20, random_state=0, p=0.1)\n",
    "print(model.percolate())\n",
    "plt.figure()\n",
    "plot_percolation(model.grid_filled)\n",
    "\n",
    "model = PercolationSimulation(n=20, random_state=0, p=0.4)\n",
    "print(model.percolate())\n",
    "plt.figure()\n",
    "plot_percolation(model.grid_filled)\n",
    "\n",
    "\n",
    "model = PercolationSimulation(n=20, random_state=0, p=0.9)\n",
    "print(model.percolate())\n",
    "plt.figure()\n",
    "plot_percolation(model.grid_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec1a17",
   "metadata": {},
   "source": [
    "Run replicate simulations across replicates with different bond occupation probabilities\n",
    "\n",
    "The percolation probability represents an effective order parameter for this system, and\n",
    "so we will attempt to calculate the percolation probability by performing many replicate\n",
    "simulations at different values of the control parameter $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d356e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import William's solution\n",
    "# from solutions.percolation import PercolationSimulation\n",
    "\n",
    "pvals = np.linspace(0, 1, 25) # control parameter for percolation phase transition\n",
    "n_reps = 200 # number of times to repeat the simulation for each p value\n",
    "\n",
    "all_percolations = list()\n",
    "for p in pvals:\n",
    "    print(\"Running replicate simulations for p = {}\".format(p), flush=True)\n",
    "    all_replicates = list()\n",
    "    for i in range(n_reps):\n",
    "        # Initialize the model\n",
    "        model = PercolationSimulation(30, p=p)\n",
    "        all_replicates.append(model.percolate())\n",
    "    all_percolations.append(all_replicates)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pvals, np.mean(np.array(all_percolations), axis=1))\n",
    "plt.xlabel('Average site occupation probability')\n",
    "plt.ylabel('Percolation probability')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pvals, np.std(np.array(all_percolations), axis=1))\n",
    "plt.xlabel('Standard deviation in site occupation probability')\n",
    "plt.ylabel('Percolation probability')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Just from curiousity, plot the distribution of cluster sizes at the percolation threshold\n",
    "## why does it appear to be bimodal?\n",
    "all_cluster_sizes = list()\n",
    "p_c = 0.407259\n",
    "n_reps = 5000\n",
    "for i in range(n_reps):\n",
    "    model = PercolationSimulation(100, p=p_c)\n",
    "    model.percolate()\n",
    "    cluster_size = np.sum(model.grid_filled == 2)\n",
    "    all_cluster_sizes.append(cluster_size)\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        print(\"Finished simulation {}\".format(i), flush=True)\n",
    "\n",
    "all_cluster_sizes = np.array(all_cluster_sizes)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(all_cluster_sizes, 50);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec9cea",
   "metadata": {},
   "source": [
    "# Experimentally verifying the $N^2$ runtime scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac88155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the experimental calculation of run-time scaling. This is ugly and dumb, but it works. \n",
    "import timeit\n",
    "\n",
    "n_to_test = np.arange(1, 500, 5)\n",
    "time_taken = []\n",
    "for n_points in n_to_test:\n",
    "    time_taken.append(timeit.timeit(\"PercolationSimulation(n=n_points, random_state=0)\", globals=globals(), number = 10))\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(n_to_test, time_taken)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c0c1a",
   "metadata": {},
   "source": [
    "# Follow-up and more information\n",
    "\n",
    "+ Directed percolation maps onto all sorts of interesting problems in physics and graph theory. There are literal applications of percolation to [flow in porous media](https://iopscience.iop.org/article/10.1088/0305-4470/14/5/012/meta), as well as [electrical conductance](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.26.5293) and [light propagation in disordered materials](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.99.234503). A great example of universality is [recent work](https://www.nature.com/articles/nphys3548) showing similar scaling exponents describe both ecological collapse and pipe turbulence, which both map onto the Directed Percolation universality class. [Here's another recent paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007508) that uses percolation theory to understand electrical signalling between neighboring cells in a biofilm. \n",
    "+ If you are interested in the mathematical theory of percolation, [Kim Christensen's notes on the subject](https://web.mit.edu/ceder/publications/Percolation.pdf) are extremely clear and interesting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd6c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975253c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413c26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8f3cda3",
   "metadata": {},
   "source": [
    "## Optional code and extras\n",
    "\n",
    "Create a simulation where we iteratively fill out one lattice, in order to make a video of our percolation simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c249d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lattice = np.zeros((50, 50))\n",
    "\n",
    "# Decide the order in which sites become blocked\n",
    "np.random.seed(0)\n",
    "all_lattice_indices = np.array(\n",
    "    [(i, j) for i in range(initial_lattice.shape[0]) for j in range(initial_lattice.shape[1])]\n",
    ")\n",
    "np.random.shuffle(all_lattice_indices)\n",
    "\n",
    "# does percolate \n",
    "all_grids = list()\n",
    "for inds in all_lattice_indices:\n",
    "    \n",
    "    initial_lattice[inds[0], inds[1]] = 1\n",
    "    model = PercolationSimulation(grid=initial_lattice)\n",
    "    model.percolate()\n",
    "\n",
    "    if (model.p > 0.3) and (model.p < 0.7):\n",
    "        all_grids.append(np.copy(model.grid_filled))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5be99bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an interactive video\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plotter(i):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plot_percolation(all_grids[i])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "interact(\n",
    "    plotter, \n",
    "    i=widgets.IntSlider(0, 0, len(all_grids) - 1, layout=Layout(width='500px'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c8d01",
   "metadata": {},
   "source": [
    "# Appendix and Extras\n",
    "\n",
    "This is William's leftover code for making videos and figures; no need to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db79a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "activity_sliding2 = activity_sliding[-500:]\n",
    "vmin = np.percentile(activity_sliding2, 1)\n",
    "# vmin = 0\n",
    "vmax = np.percentile(activity_sliding2, 99.8)\n",
    "\n",
    "# Assuming frames is a numpy array with shape (num_frames, height, width)\n",
    "frames = np.array(activity_sliding2).copy() \n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# img = plt.imshow(frames[0], vmin=vmin, vmax=vmax);\n",
    "plt.xticks([]); plt.yticks([])\n",
    "# tight margins\n",
    "plt.margins(0,0)\n",
    "plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "def update(frame):\n",
    "    plot_percolation(all_grids[::2])\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=all_grids[::2], interval=50)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dca61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) I used this code to export still images, and then make a video from them using\n",
    "# the command-line tool ffmpeg\n",
    "\n",
    "\n",
    "for i in range(len(all_grids[::2]) - 1):\n",
    "    \n",
    "    \n",
    "    out_path = \"private_dump/percolation/frame\" + str(i).zfill(4) + \".png\"\n",
    "\n",
    "    plt.figure()\n",
    "    plot_percolation(all_grids[::2][i])\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.set_aspect(1, adjustable='box')\n",
    "\n",
    "    plt.savefig(out_path, bbox_inches='tight', pad_inches=0.0, dpi=160)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53557b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) I used this code to stitch the images together into a video. The %%bash magic tells\n",
    "# iPython to treat these lines as bash commands, rather than Python. I then use the \n",
    "# command-line tool `ffmpeg` to stitch the images together into a video.\n",
    "\n",
    "%%bash\n",
    "ffmpeg -r 60 -i private_dump/percolation/frame%04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -vcodec libx264 -pix_fmt yuv420p private_dump/percolation/vid2.mov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf4944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
